<html>
    <head>
    </head>
    <script>
    function PCMPlayer(option) {
    this.init(option);
}

PCMPlayer.prototype.init = function(option) {
    var defaults = {
        encoding: '16bitInt',
        channels: 1,
        sampleRate: 8000,
        flushingTime: 1000
    };
    this.option = Object.assign({}, defaults, option);
    this.samples = new Float32Array();
    this.flush = this.flush.bind(this);
    this.interval = setInterval(this.flush, this.option.flushingTime);
    this.maxValue = this.getMaxValue();
    this.typedArray = this.getTypedArray();
    this.createContext();
};

PCMPlayer.prototype.getMaxValue = function () {
    var encodings = {
        '8bitInt': 128,
        '16bitInt': 32768,
        '32bitInt': 2147483648,
        '32bitFloat': 1
    }

    return encodings[this.option.encoding] ? encodings[this.option.encoding] : encodings['16bitInt'];
};

PCMPlayer.prototype.getTypedArray = function () {
    var typedArrays = {
        '8bitInt': Int8Array,
        '16bitInt': Int16Array,
        '32bitInt': Int32Array,
        '32bitFloat': Float32Array
    }

    return typedArrays[this.option.encoding] ? typedArrays[this.option.encoding] : typedArrays['16bitInt'];
};

PCMPlayer.prototype.createContext = function() {
    this.audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    // context needs to be resumed on iOS and Safari (or it will stay in "suspended" state)
    this.audioCtx.resume();
    this.audioCtx.onstatechange = () => console.log(this.audioCtx.state);   // if you want to see "Running" state in console and be happy about it

    this.gainNode = this.audioCtx.createGain();
    this.gainNode.gain.value = 1;
    this.gainNode.connect(this.audioCtx.destination);
    this.startTime = this.audioCtx.currentTime;
};

PCMPlayer.prototype.isTypedArray = function(data) {
    return (data.byteLength && data.buffer && data.buffer.constructor == ArrayBuffer);
};

PCMPlayer.prototype.feed = function(data) {
    if (!this.isTypedArray(data)) return;
    data = this.getFormatedValue(data);
    var tmp = new Float32Array(this.samples.length + data.length);
    tmp.set(this.samples, 0);
    tmp.set(data, this.samples.length);
    this.samples = tmp;
};

PCMPlayer.prototype.getFormatedValue = function(data) {
    var data = new this.typedArray(data.buffer),
        float32 = new Float32Array(data.length),
        i;

    for (i = 0; i < data.length; i++) {
        float32[i] = data[i] / this.maxValue;
    }
    return float32;
};

PCMPlayer.prototype.volume = function(volume) {
    this.gainNode.gain.value = volume;
};

PCMPlayer.prototype.destroy = function() {
    if (this.interval) {
        clearInterval(this.interval);
    }
    this.samples = null;
    this.audioCtx.close();
    this.audioCtx = null;
};

PCMPlayer.prototype.flush = function() {
    if (!this.samples.length) return;
    var bufferSource = this.audioCtx.createBufferSource(),
        length = this.samples.length / this.option.channels,
        audioBuffer = this.audioCtx.createBuffer(this.option.channels, length, this.option.sampleRate),
        audioData,
        channel,
        offset,
        i,
        decrement;

    for (channel = 0; channel < this.option.channels; channel++) {
        audioData = audioBuffer.getChannelData(channel);
        offset = channel;
        decrement = 50;
        for (i = 0; i < length; i++) {
            audioData[i] = this.samples[offset];
            /* fadein */
            if (i < 50) {
                audioData[i] =  (audioData[i] * i) / 50;
            }
            /* fadeout*/
            if (i >= (length - 51)) {
                audioData[i] =  (audioData[i] * decrement--) / 50;
            }
            offset += this.option.channels;
        }
    }

    if (this.startTime < this.audioCtx.currentTime) {
        this.startTime = this.audioCtx.currentTime;
    }
    console.log('start vs current '+this.startTime+' vs '+this.audioCtx.currentTime+' duration: '+audioBuffer.duration);
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(this.gainNode);
    bufferSource.start(this.startTime);
    this.startTime += audioBuffer.duration;
    this.samples = new Float32Array();
};

        // websocket地址
        // 填写的是esp32服务器的ip地址
        let websocket_url = 'ws://192.168.137.35:80/ws';
        let bufferSize = 8192,
            AudioContext,
            context,
            processor,
            input,
            globalStream,
            websocket;

        // 初始化浏览器的websocket
        initWebSocket();

        // 初始化播放器
        let player = new PCMPlayer({
            encoding: '16bitInt',
            channels: 1,
            // esp32以16000Hz采集声音，浏览器以32000Hz播放声音
            sampleRate: 32000,
            flushingTime: 2000
        });

        // 通过浏览器的麦克风api采集声音
        function startRecording() {
            streamStreaming = true;
            AudioContext = window.AudioContext || window.webkitAudioContext;
            context = new AudioContext({
                latencyHint: 'interactive',
            });
            processor = context.createScriptProcessor(bufferSize, 1, 1);
            processor.connect(context.destination);
            context.resume();

            let handleSuccess = function (stream) {
                const sampleRate = stream.getAudioTracks()[0].getSettings().sampleRate;
                console.log(sampleRate);
                globalStream = stream;
                input = context.createMediaStreamSource(stream);
                input.connect(processor);

                processor.onaudioprocess = function (e) {
                    // 以48000Hz采集声音数据
                    let left = e.inputBuffer.getChannelData(0);
                    // 降采样为32000Hz的声音数据
                    let left16 = downsampleBuffer(left, 48000, 32000);
                    // 将声音数据通过websocket发送给esp32
                    websocket.send(left16);
                };
            };

            navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then(handleSuccess);
        }

        // 停止采集声音
        function stopRecording() {
            streamStreaming = false;

            let track = globalStream.getTracks()[0];
            track.stop();

            input.disconnect(processor);
            processor.disconnect(context.destination);
            context.close().then(function () {
                input = null;
                processor = null;
                context = null;
                AudioContext = null;
            });
        }

        // 初始化websocket
        function initWebSocket() {
            websocket = new WebSocket(websocket_url);
            websocket.onopen = function () {
                document.getElementById("webSocketStatus").innerHTML = '已连接';
            };
            websocket.onclose = function (e) {
                document.getElementById("webSocketStatus").innerHTML = '未连接';
            };
            websocket.onmessage = function (e) {
                e.data.arrayBuffer().then(buffer => {
                    player.feed(new Int16Array(buffer));
                });
            };
        }

        function downsampleBuffer(buffer, sampleRate, outSampleRate) {
            let sampleRateRatio = sampleRate / outSampleRate;
            let newLength = Math.round(buffer.length / sampleRateRatio);
            let result = new Int16Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            while (offsetResult < result.length) {
                let nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                let accum = 0;
                let count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }

                result[offsetResult] = Math.min(1, accum / count) * 0x7FFF;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }

            return result.buffer;
        }
    </script>

    <body>
        <!-- <iframe src="http://192.168.137.35:81/jpeg" style="width: 240px; height: 240px"></iframe><br> -->
        <button onclick='startRecording()'>开始采集声音</button>
        <button onclick='stopRecording()'>停止采集声音</button>
        <br />
        <div>WebSocket: <span id="webSocketStatus">未连接</span></div>
    </body>
</html>
